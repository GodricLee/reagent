SHARED_Y_WEBSOCKET_SERVER_SECRET=xxxx

GITHUB_CLIENT_ID=xxxx
GITHUB_CLIENT_SECRET=xxxx

SESSION_SECRET=xxxx

# this will only work in development mode, but we still use a password to be eeextra safe
DEV_LOGIN_PASSWORD=xxxx

MINIO_ROOT_PASSWORD=xxxx

# INTERNAL_HOST is used to make S3 API requests from within the Docker network.
# PRESIGNED_HOST will be used to make S3 API requests from outside the Docker network, e.g. from the user's browser.
# later, EXTERNAL_URL will be used for simple GET operations on a public-facing bucket.

# in dev running the minio container, INTERNAL_HOST will need to be `minio` or whatever the
#  Docker container is called -- you can use an externally-accessible URL, but it's a little
#  silly to specify the reverse proxy here in this config and then go through the public Internet.
# for PRESIGNED_HOST, you do want a URL accessible by the user's browser for the S3 API.
# this may or may not be the same as the host used in EXTERNAL_URL. when running minio, it will be:
# OBJECT_STORAGE_INTERNAL_HOST=minio
# OBJECT_STORAGE_PRESIGNED_HOST=http://objects.dev.rea.gent
# OBJECT_STORAGE_NOGGIN_RUN_OUTPUTS_EXTERNAL_URL=http://objects.dev.rea.gent/noggin-run-outputs

# but when running, e.g. with cloudflare R2, the public access URL doesn't match the S3 API url.
# since the object storage is legitimately external, even the "INTERNAL_HOST" (the host used to make
#   requests from the web server) will be an external API host:
# OBJECT_STORAGE_INTERNAL_HOST=xxxx.r2.cloudflarestorage.com
# OBJECT_STORAGE_PRESIGNED_HOST=xxxx.r2.cloudflarestorage.com
# OBJECT_STORAGE_NOGGIN_RUN_OUTPUTS_EXTERNAL_URL=https://noggin-run-outputs-dev-tja.rgdata.net

OBJECT_STORAGE_INTERNAL_HOST=minio
OBJECT_STORAGE_PRESIGNED_HOST=objects.dev.rea.gent
OBJECT_STORAGE_INTERNAL_PORT=9000
OBJECT_STORAGE_INTERNAL_USE_SSL=false

# external URLs are ideally truly externally accessible, so that remote APIs can access files.
# e.g. can reverse-proxy the minio server to a public URL, or just use an actual remote object store.
# if this isn't possible, at least set external URL to something accessible on the Docker host machine.
# don't use a trailing slash.
OBJECT_STORAGE_NOGGIN_RUN_OUTPUTS_BUCKET=noggin-run-outputs
OBJECT_STORAGE_NOGGIN_RUN_OUTPUTS_BUCKET_EXTERNAL_URL=http://objects.dev.rea.gent/noggin-run-outputs
OBJECT_STORAGE_NOGGIN_RUN_INPUTS_BUCKET=noggin-run-inputs
OBJECT_STORAGE_NOGGIN_RUN_INPUTS_BUCKET_EXTERNAL_URL=http://objects.dev.rea.gent/noggin-run-inputs
OBJECT_STORAGE_NOGGIN_FILES_BUCKET=noggin-files
OBJECT_STORAGE_NOGGIN_FILES_BUCKET_EXTERNAL_URL=http://objects.dev.rea.gent/noggin-files

OBJECT_STORAGE_ACCESS_KEY=xxxx
OBJECT_STORAGE_SECRET_KEY=xxxx

# 'path' if host.ext/bucketname, 'subdomain' if bucketname.host.ext
# (this is for the *s3 api*, not for external URL access, which can be whatever)
OBJECT_STORAGE_PATH_TYPE=path